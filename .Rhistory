df <- df[!is.na(df$hashtags),]
hash_dfm <- dfm(df$hashtags)
hash_dfm <- dfm_remove(dfmat, hashtag_remove)# Document-feature matrix
toptag <- names(topfeatures(hash_dfm, n_top)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(hash_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
topgat_fcm <- tokens_remove(toks, pattern = stopwords("en"))
##draw semantic network plot
quanteda::textplot_network(topgat_fcm, min_freq = 1, edge_color = "grey",vertex_color ="#538797")
}
hashtags_network(pre_df)
hashtags_network <- function(df, hashtag_remove = "cultura", n_top = 40){
for(i in 1:nrow(df)){
df$hashtags[[i]] <- tolower(paste(paste0("#", df$hashtags[[i]]), collapse = " "))
}
df$hashtags <- gsub("#na", NA, df$hashtags)
df <- df[!is.na(df$hashtags),]
hash_dfm <- dfm(df$hashtags)
hash_dfm <- dfm_remove(hash_dfm, hashtag_remove)# Document-feature matrix
toptag <- names(topfeatures(hash_dfm, n_top)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(hash_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
topgat_fcm <- tokens_remove(toks, pattern = stopwords("en"))
##draw semantic network plot
quanteda::textplot_network(topgat_fcm, min_freq = 1, edge_color = "grey",vertex_color ="#538797")
}
hashtags_network(pre_df)
df <- pre_df
for(i in 1:nrow(df)){
df$hashtags[[i]] <- tolower(paste(paste0("#", df$hashtags[[i]]), collapse = " "))
}
df$hashtags <- gsub("#na", NA, df$hashtags)
df <- df[!is.na(df$hashtags),]
hash_dfm <- dfm(df$hashtags)
hash_dfm <- dfm_remove(hash_dfm, hashtag_remove)# Document-feature matrix
toptag <- names(topfeatures(hash_dfm, n_top)) # Most important hashtags; we dont want to plot every hashtag
n_top = 40
toptag <- names(topfeatures(hash_dfm, n_top)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(hash_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
##draw semantic network plot
quanteda::textplot_network(topgat_fcm, min_freq = 1, edge_color = "grey",vertex_color ="#538797")
hashtags_network <- function(df, hashtag_remove = "#cultura", n_top = 40){
for(i in 1:nrow(df)){
df$hashtags[[i]] <- tolower(paste(paste0("#", df$hashtags[[i]]), collapse = " "))
}
df$hashtags <- gsub("#na", NA, df$hashtags)
df <- df[!is.na(df$hashtags),]
hash_dfm <- dfm(df$hashtags)
hash_dfm <- dfm_remove(hash_dfm, hashtag_remove)# Document-feature matrix
toptag <- names(topfeatures(hash_dfm, n_top)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(hash_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
##draw semantic network plot
quanteda::textplot_network(topgat_fcm, min_freq = 1, edge_color = "grey",vertex_color ="#538797")
}
hashtags_network(pre_df)
hashtags_network_hub <- function(df, n_top = 40){
for(i in 1:nrow(df)){
df$hashtags[[i]] <- tolower(paste(paste0("#", df$hashtags[[i]]), collapse = " "))
}
df$hashtags <- gsub("#na", NA, df$hashtags)
df <- df[!is.na(df$hashtags),]
hash_dfm <- tokens(df$hashtags) # Document-feature matrix
fcmat <- fcm(hash_dfm , context = "window", tri = FALSE) # Feature-occurance matrix which shows the network structure
##selecting keywords inside fcmat
tmp <- fcmat[, hub]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
fcm_local <- fcm_select(fcmat, pattern = c(tmp, hub))
##text plot
quanteda::textplot_network(fcm_local, min_freq = 0.1, edge_color = "grey",vertex_color ="#538797")
}
hashtags_network_hub(pre_df)
keyword_network <- function(df, n_top = 40){
toks <- tokens(df$text, remove_punct = TRUE, remove_symbols = TRUE, verbose = TRUE)
toks <- tokens_tolower(toks)
toks <- tokens_remove(toks, padding = FALSE, min_nchar =3)
#toks <- tokens_wordstem(toks, language = language)
## A feature co-occurrence matrix
fcmat <-quanteda::fcm(toks, context = "window", tri = FALSE)
##reduce only top words
feat <-  names(topfeatures(fcmat, n_top))
##subset top 40 words
fcm_1 <- fcm_select(fcmat, pattern = feat)
##draw semantic network plot
quanteda::textplot_network(fcm_1, min_freq = 1, edge_color = "grey",vertex_color ="#538797")
}
keyword_network(pre_df)
hashtags_df(pre_df)
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies[1]
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
df <- pre_df
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies[1]
hashtag_frequencies[!row.names(hashtag_frequencies)%in% "#cultura",]
hashtag_frequencies[!row.names(hashtag_frequencies)%in% "#cultura"]
hashtags_df <- function(df, hashtag_remove, top_n = 10){
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies[!row.names(hashtag_frequencies)%in% hashtag_remove]
print(kable(head(hashtag_frequencies, top_n), "simple", caption = paste("Top", top_n, "hashtags")))
}
hashtags_df(pre_df)
hashtags_df(pre_df, "#cultura")
hashtags_df <- function(df, hashtag_remove, top_n = 10){
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies <- hashtag_frequencies[!row.names(hashtag_frequencies)%in% hashtag_remove]
print(kable(head(hashtag_frequencies, top_n), "simple", caption = paste("Top", top_n, "hashtags")))
}
hashtags_df(pre_df, "#cultura")
df <- pre_df
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
View(hashtag_frequencies)
hashtags_df <- function(df, hashtag_remove, top_n = 10){
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
#hashtag_frequencies <- hashtag_frequencies[!row.names(hashtag_frequencies)%in% hashtag_remove]
print(kable(head(hashtag_frequencies, top_n), "simple", caption = paste("Top", top_n, "hashtags")))
}
View(hashtag_frequencies)
hashtags_df(pre_df)
hashtags_df <- function(df, hashtag_remove, top_n = 10){
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
all_hashtags <- gsub("#Na", "", all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies <- hashtag_frequencies[!row.names(hashtag_frequencies)%in% hashtag_remove]
print(kable(head(hashtag_frequencies, top_n), "simple", caption = paste("Top", top_n, "hashtags")))
}
hashtags_df(pre_df, "#cultura")
hashtags_df <- function(df, hashtag_remove, top_n = 10){
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
all_hashtags <- gsub("#NA", "", all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies <- hashtag_frequencies[!row.names(hashtag_frequencies)%in% hashtag_remove]
print(kable(head(hashtag_frequencies, top_n), "simple", caption = paste("Top", top_n, "hashtags")))
}
hashtags_df(pre_df, "#cultura")
hashtags_df <- function(df, hashtag_remove, top_n = 10){
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
#all_hashtags <- gsub("#NA", "", all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies <- hashtag_frequencies[!row.names(hashtag_frequencies)%in% c(hashtag_remove, "#NA")]
print(kable(head(hashtag_frequencies, top_n), "simple", caption = paste("Top", top_n, "hashtags")))
}
hashtags_df(pre_df, "#cultura")
keyword_df <- function(df, keyword_remove, top_n = 10){
toks <- tokens(df$text, remove_punct = TRUE, remove_symbols = TRUE, verbose = TRUE)
toks <- tokens_tolower(toks)
toks <- tokens_remove(toks, padding = FALSE, min_nchar =3)
hash_dfm <- dfm(toks) # Document-feature matrix
hash_dfm <- dfm_remove(hash_dfm, keyword_remove)
toptag <- sort(topfeatures(hash_dfm, top_n), decreasing = TRUE)
toptag <- data.frame(toptag)
toptag <- tibble::rownames_to_column(toptag, "keyword")
colnames(toptag) <- c("keyword", "freq")
print(kable(toptag, "simple", caption = paste("Top", top_n, "keyword")))
}
keyword_df(pre_df, "cultura")
df <- readRDS("F:/Bea/PostDoc/RESEARCH/ComTxt/data-raw/basic_tweets.Rds")
toks <- tokens(df$text, remove_punct = TRUE, remove_symbols = TRUE, verbose = TRUE)
toks <- tokens_tolower(toks)
toks <- tokens_remove(toks, padding = FALSE, min_nchar =3)
## A feature co-occurrence matrix
fcmat <-quanteda::fcm(toks, context = "window", tri = FALSE)
hub = "arte"
##selecting keywords inside fcmat
tmp <- fcmat[, hub]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
tmp
sort(tmp, decreasing = T)
sort(tmp, decreasing = TRUE)
sort(tmp[tmp$degree,], decreasing = TRUE)
sort(tmp$degree, decreasing = TRUE)
sort(tmp$degree, decreasing = FALSE)
View(tmp)
hub = "literatura"
##selecting keywords inside fcmat
tmp <- fcmat[, hub]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
View(tmp)
keyword_network <- function(df, keyword_remove, n_top = 40){
toks <- tokens(df$text, remove_punct = TRUE, remove_symbols = TRUE, verbose = TRUE)
toks <- tokens_tolower(toks)
toks <- tokens_remove(toks, padding = FALSE, min_nchar =3)
#toks <- tokens_wordstem(toks, language = language)
## A feature co-occurrence matrix
fcmat <-quanteda::fcm(toks, context = "window", tri = FALSE)
##reduce only top words
feat <-  names(topfeatures(fcmat, n_top))
##subset top 40 words
fcm_1 <- fcm_select(fcmat, pattern = feat)
fcm_1 <- fcm_remove(fcm_1, keyword_remove)
##draw semantic network plot
quanteda::textplot_network(fcm_1, min_freq = 1, edge_color = "grey",vertex_color ="#538797")
}
keyword_network(df)
keyword_network(df, keyword_remove = "cultura")
hub = "que"
##selecting keywords inside fcmat
tmp <- fcmat[, hub]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
View(tmp)
nodes_degree <- tmp[tmp$nodes == hub, ]$degree
high_nodes <- tmp[tmp$degree > nodes_degree, ]$nodes
fcm_local <- fcm_select(fcmat, pattern = c(tmp, hub))
fcm_local <- fcm_remove(fcm_local, c(keyword_remove, high_nodes))
keyword_remove = "cultura"
fcm_local <- fcm_remove(fcm_local, c(keyword_remove, high_nodes))
##text plot
quanteda::textplot_network(fcm_local, min_freq = 0.1, edge_color = "grey",vertex_color ="#538797")
##reduce only top words
feat <-  names(topfeatures(fcm_local, n_top))
n_top <- 40
##reduce only top words
feat <-  names(topfeatures(fcm_local, n_top))
##subset top 40 words
fcm_local <- fcm_select(fcm_local, pattern = feat)
##text plot
quanteda::textplot_network(fcm_local, min_freq = 0.1, edge_color = "grey",vertex_color ="#538797")
keyword_network_hub <- function(df, hub, n_top){
toks <- tokens(df$text, remove_punct = TRUE, remove_symbols = TRUE, verbose = TRUE)
toks <- tokens_tolower(toks)
toks <- tokens_remove(toks, padding = FALSE, min_nchar =3)
## A feature co-occurrence matrix
fcmat <-quanteda::fcm(toks, context = "window", tri = FALSE)
##selecting keywords inside fcmat
tmp <- fcmat[, hub]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
nodes_degree <- tmp[tmp$nodes == hub, ]$degree
high_nodes <- tmp[tmp$degree > nodes_degree, ]$nodes
fcm_local <- fcm_select(fcmat, pattern = c(tmp, hub))
fcm_local <- fcm_remove(fcm_local, high_nodes)
##reduce only top words
feat <-  names(topfeatures(fcm_local, n_top))
##subset top 40 words
fcm_local <- fcm_select(fcm_local, pattern = feat)
##text plot
quanteda::textplot_network(fcm_local, min_freq = 0.1, edge_color = "grey",vertex_color ="#538797")
}
keyword_network_hub(df, hub = "que")
keyword_network_hub(df, hub = "que", n_top = 40)
for(i in 1:nrow(df)){
df$hashtags[[i]] <- tolower(paste(paste0("#", df$hashtags[[i]]), collapse = " "))
}
df$hashtags <- gsub("#na", NA, df$hashtags)
df <- df[!is.na(df$hashtags),]
hash_dfm <- tokens(df$hashtags) # Document-feature matrix
fcmat <- fcm(hash_dfm , context = "window", tri = FALSE) # Feature-occurance matrix which shows the network structure
hub = "#literatura"
##selecting keywords inside fcmat
tmp <- fcmat[, hub]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
nodes_degree <- tmp[tmp$nodes == hub, ]$degree
high_nodes <- tmp[tmp$degree > nodes_degree, ]$nodes
fcm_local <- fcm_select(fcmat, pattern = c(tmp, hub))
fcm_local <- fcm_remove(fcm_local, high_nodes)
##reduce only top words
feat <-  names(topfeatures(fcm_local, n_top))
fcm_local <- fcm_select(fcmat, pattern = c(tmp, hub))
##text plot
quanteda::textplot_network(fcm_local, min_freq = 0.1, edge_color = "grey",vertex_color ="#538797")
hashtags_df <- function(df, hashtag_remove, top_n = 10){
all_hashtags <- tolower(unlist(df$hashtags))
all_hashtags <- paste0("#",all_hashtags)
#all_hashtags <- gsub("#NA", "", all_hashtags)
hashtag_frequencies <- sort(table(all_hashtags), decreasing = TRUE)
hashtag_frequencies <- hashtag_frequencies[!row.names(hashtag_frequencies)%in% c(hashtag_remove, "#NA")]
print(kable(head(hashtag_frequencies, top_n), "simple", caption = paste("Top", top_n, "hashtags")))
}
library(ComTxt)
tweets_df_clean <- readRDS("F:/Bea/PostDoc/RESEARCH/ComTxt/data-raw/tweets_df_clean.Rds")
View(tweets_df_clean)
tweets_df_clean$geo_coord[[1]]
tweets_df_clean$geo_coord[[1]][1]
df <- tweets_df_clean
for(i in 1:nrow(df)){
dd <- df$geo_coord[[i]][2]
df$geo_coord[[i]][[2]] <- df$geo_coord[[i]][[1]]
df$geo_coord[[i]][[1]] <- dd
}
i =
i
i
dd <- df$geo_coord[[i]][2]
dd
df$geo_coord[[i]][[1]]
df$geo_coord[[1]][[1]]
df$geo_coord[[2]]
df$geo_coord[[1]]
is.na(df$geo_coord[[2]])
length(df$geo_coord[[2]])
length(df$geo_coord[[2]]) == 0
length(df$geo_coord[[1]]) == 0
i = 1
i = 2
if(length(df$geo_coord[[i]]) = 0){
df$geo_coord[[i]][[1]] <- NA
df$geo_coord[[i]][[2]] <- NA
}
if(length(df$geo_coord[[i]]) == 0){
df$geo_coord[[i]][[1]] <- NA
df$geo_coord[[i]][[2]] <- NA
}
df$geo_coord[[2]]
i
dd[[i]] <- df$geo_coord[[i]][2]
dd
dd <- df$geo_coord[[i]][2]
dd
for(i in 1:nrow(df)){
if(length(df$geo_coord[[i]]) == 0){
df$geo_coord[[i]][[1]] <- NA
df$geo_coord[[i]][[2]] <- NA
}
dd <- df$geo_coord[[i]][1]
df$geo_coord[[i]][[1]] <- df$geo_coord[[i]][[2]]
df$geo_coord[[i]][[2]] <- dd
}
df <- readRDS("F:/Bea/PostDoc/RESEARCH/ComTxt/data-raw/basic_tweets.Rds")
network_data_function <- function(.e){
to = dd$mentions_screen_name
}
network_data_function <- function(df){
to = df$mentions_screen_name
}
lapply(df$mentions_screen_name, function(x))
lapply(df$mentions_screen_name, function(x))
lapply(df$mentions_screen_name, list())
lapply(df$mentions_screen_name, list)
lapply(df$mentions_screen_name, as.list)
lapply(df$mentions_screen_name, data.frame)
dd <- lapply(df$mentions_screen_name, data.frame)
View(dd)
dd[[1]]
net <- list(to = df$screen_name, from =lapply(df$mentions_screen_name, data.frame))
net[[1]]
head(df$screen_name)
dd <- lapply(df$mentions_screen_name, data.frame)
head(dd)
dd[[1]]
class(dd[[1]])
dd[[1]] <- cbind(df$screen_name[[1]], dd[[1]])
head(dd)
dd[[1]] <- cbind(from = df$screen_name[[1]], to = dd[[1]])
head(dd)
dd[[2]] <- cbind(from = df$screen_name[[2]], to = dd[[2]])
head[[2]]
head(dd)
lapply(df, cbind(from= screen_name, to = dd))
lapply(df, cbind(from= df$screen_name, to = dd))
lapply(df, cbind, dd)
d_1 <- lapply(df$screen_name, cbind, dd)
View(d_1)
d_1[[1]]
dd[[1]]
dd <- lapply(df$mentions_screen_name, data.frame)
d_1 <- lapply(df$screen_name, cbind, dd)
head(d_1)
d_1 <- lapply(df, function(x){
dd <- lapply(df$mentions_screen_name, data.frame)
data.frame(from = df$screen_name, to = dd)
})
d_1 <- lapply(df, function(x){
data.frame(from = df$screen_name, to = dd)
})
d_1 <- lapply(df$screen_name, function(x){
data.frame(from = df$screen_name, to = dd)
})
d_1 <- lapply(df$screen_name, function(x){
cbind(from = df$screen_name, to = dd)
})
head(d_1)
length(dd)
dd[[i]]
i = 1
dd[[i]]
tmp <- as.data.frame(from = df$screen_name[[i]], to = dd[[i]])
tmp <- data.frame(from = df$screen_name[[i]], to = dd[[i]])
View(tmp)
tmp <- list()
for(i in 1:length(dd)){
tmp[[i]] <- data.frame(from = df$screen_name[[i]], to = dd[[i]])
}
head(tmp)
tmp <- do.call(rbind.data.frame, tmp)
View(tmp)
colnames(tmp) <- c("from", "to")
df.network <- tmp
i = 1
length(tmp[tmp[,1] == df.network$from[i],])
tmp[tmp[,1]
]
tmp[,1]
View(df.network)
length(tmp[tmp[,1]==df.network$to[i],])
length(tmp[df.network$to == df.network$from[i],])
tmp[df.network$to == df.network$from[i],]
df.network$to %in% "BallabrigaAna"
df.network$from %in% "BallabrigaAna"
length(df.network$from %in% "BallabrigaAna"==TRUE)
df.network[df.network$from == "BallabrigaAna",]
nrow(df.network[df.network$from == "BallabrigaAna",])
nrow(tmp[tmp[,1]==df.network$to[i],])
i
df.network$to[i]
tmp[,1]
tmp
tmp[tmp$from == tmp$from[1] | tmp$to == tmp$from[1] ,]
df.edges <- df.network
edges <- df_edges
nodes.1 <- as.data.frame(c(edges$from,edges$to))
df_edges <- df.network
edges <- df_edges
nodes.1 <- as.data.frame(c(edges$from,edges$to))
nodes.2 <- nodes.1[!duplicated(nodes.1[,1]), ]
nodes <- data.frame(nodes.2)
net <- igraph::graph_from_data_frame(d = edges, directed = T, vertices = nodes)
edges
plot.igraph(net,
layout = layout_nicely(net),
vertex.color = "#F8F7F2",
#vertex.size = degree(net, mode="all")*input$size_vertex,
vertex.frame.color = "gray",
#vertex.label = NA,
vertex.label.color = "#538797",
#vertex.label.cex = degree(net, mode="all")*input$size_vertex_label,
vertex.label.dist= 2,
edge.arrow.size = 0.1,
edge.color = colrs[as.numeric(as.factor(E(net)$type))],
edge.width = 0.1,
edge.lty = 2,
asp = 0.4,
margin = 0,
)
libraru(igraph)
library(igraph)
plot.igraph(net,
layout = layout_nicely(net),
vertex.color = "#F8F7F2",
#vertex.size = degree(net, mode="all")*input$size_vertex,
vertex.frame.color = "gray",
#vertex.label = NA,
vertex.label.color = "#538797",
#vertex.label.cex = degree(net, mode="all")*input$size_vertex_label,
vertex.label.dist= 2,
edge.arrow.size = 0.1,
edge.color = colrs[as.numeric(as.factor(E(net)$type))],
edge.width = 0.1,
edge.lty = 2,
asp = 0.4,
margin = 0,
)
plot.igraph(net,
layout = layout_nicely(net),
vertex.color = "#F8F7F2",
#vertex.size = degree(net, mode="all")*input$size_vertex,
vertex.frame.color = "gray",
#vertex.label = NA,
vertex.label.color = "#538797",
#vertex.label.cex = degree(net, mode="all")*input$size_vertex_label,
vertex.label.dist= 2,
edge.arrow.size = 0.1,
#edge.color = colrs[as.numeric(as.factor(E(net)$type))],
edge.width = 0.1,
edge.lty = 2,
asp = 0.4,
margin = 0,
)
plot.igraph(net,
layout = layout_nicely(net),
vertex.color = "#F8F7F2",
vertex.size = degree(net, mode="all")*0.3,
vertex.frame.color = "gray",
#vertex.label = NA,
vertex.label.color = "#538797",
#vertex.label.cex = degree(net, mode="all")*input$size_vertex_label,
vertex.label.dist= 2,
edge.arrow.size = 0.1,
#edge.color = colrs[as.numeric(as.factor(E(net)$type))],
edge.width = 0.1,
edge.lty = 2,
asp = 0.4,
margin = 0,
)
