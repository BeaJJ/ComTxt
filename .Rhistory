##language specific
location_df[,2] <- tolower(location_df[,2])##lowercase
location_df[,1] <- tolower(location_df[,1])##lowercase
location_df <-
location_df %>%
mutate(
country = ifelse(location_df$city %in% multi_name, location_country, location_df$country)
)
location_df <-
location_df %>%
mutate(
country = ifelse(location_df$country %in% multi_name, location_country, location_df$country)
)
## if cities names is spain add to country column----
location_df <- as.data.frame(location_df)
location_df <-
location_df %>%
mutate(
country =ifelse(location_df[,1] == location_country, location_country, location_df[,2])
)
location_df[,1] <- gsub("^\\s+|\\s+$", "", location_df[,1])##deleting space
location_df[,2] <- gsub("^\\s+|\\s+$", "", location_df[,2])##deleting space
##geocode selecting
#geo <- list()
#for(i in 1:length(df$location)){
# if(is.na(df$geo_coords[[i]][[1]])){
#    geo[[i]] <- list(lat = NA, lng = NA)
#  } else {
#   geo[[i]] <- list(lat = df$geo_coords[[i]][[1]], lng = df$geo_coords[[i]][[2]], country = location_country)
# }
#}
#geo <- reduce(geo, bind_rows)
##location_df :combining loctaion_df and location tmp
#location_df <- cbind(location_df, geo[,3])
#for(i in 1:nrow(location_df)){
#  if (is.na(location_df[[i,3]]) == FALSE){
#   location_df[[i,2]] <- as.character(location_df[[i,3]])
# }
#}
location_df <- location_df[,1:2]
data("world.cities")
## now lets find the cities cities
world.cities$country.etc <- tolower(world.cities$country.etc)
city_df <- world.cities[world.cities$country.etc == location_country, ]
city_df$name <- tolower(city_df$name)
location_df <-
location_df %>%
mutate(
country = ifelse(location_df$city %in% city_df$name, location_country, location_df$country)
)
## add to text_clean data fram
df <- subset(df, select = -c(location, country))
df <- data.frame(df, location_df)
## add lat lang from geo_coord
#df <- cbind(df, geo[,1:2])
city_df <- world.cities[world.cities$country.etc == location_country, ]
city_df$name <- tolower(city_df$name)
#geom <- list()
for(i in 1:nrow(df)){
if(nrow(city_df[city_df$name == df$city[i],])==1){
df$lat[[i]] <- city_df[city_df$name == df$city[i],]$lat
df$lng[[i]] <- city_df[city_df$name == df$city[i],]$long
}
if(nrow(city_df[city_df$name == df$city[i],])==0) {
df$lat[[i]] <- NA
df$lng[[i]] <- NA
}
}
df <- df[which(df$country == location_country),]
for(i in 1:nrow(df)){
if(is.na(df$lat[i])==TRUE){
if(is.na(df$geo_coords[[i]][[2]])==TRUE){
df$lat[[i]] <- NA
df$lng[[i]] <-NA
}else{
df$lat[[i]] <- df$geo_coords[[i]][[1]]
df_tweets$lng[[i]] <- df$geo_coords[[i]][[2]]
}
}else{
df$lat[[i]] <- df$lat[[i]]
df$lng[[i]] <- df$lng[[i]]
}
}
return(df)
}
hashtags_network <- function(df, hashtag_remove = "#cultura", top_n = 40){
for(i in 1:nrow(df)){
df$hashtags[[i]] <- tolower(paste(paste0("#", df$hashtags[[i]]), collapse = " "))
}
df$hashtags <- gsub("#na", NA, df$hashtags)
df$hashtags <- iconv(df$hashtags,from="UTF-8",to="ASCII//TRANSLIT")
df <- df[!is.na(df$hashtags),]
hash_dfm <- dfm(df$hashtags)
hash_dfm <- dfm_remove(hash_dfm, hashtag_remove)# Document-feature matrix
toptag <- names(topfeatures(hash_dfm, top_n)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(hash_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
##draw semantic network plot
quanteda.textplots::textplot_network(topgat_fcm, min_freq = 1, edge_color = "grey",vertex_color ="#538797")
}
hashtags_network_hub <- function(df, hub, top_n = 40){
for(i in 1:nrow(df)){
df$hashtags[[i]] <- tolower(paste(paste0("#", df$hashtags[[i]]), collapse = " "))
}
df$hashtags <- gsub("#na", NA, df$hashtags)
df$hashtags <- iconv(df$hashtags,from="UTF-8",to="ASCII//TRANSLIT")
df <- df[!is.na(df$hashtags),]
hash_dfm <- tokens(df$hashtags) # Document-feature matrix
fcmat <- fcm(hash_dfm , context = "window", tri = FALSE) # Feature-occurance matrix which shows the network structure
##selecting keywords inside fcmat
tmp <- fcmat[, hub]
tmp <- convert(tmp, to = "data.frame")
colnames(tmp) <- c("nodes", "degree")
tmp <- tmp[tmp$degree > 0, ]
nodes_degree <- tmp[tmp$nodes == hub, ]$degree
high_nodes <- tmp[tmp$degree > nodes_degree, ]$nodes
fcm_local <- fcm_select(fcmat, pattern = c(tmp, hub))
fcm_local <- fcm_remove(fcm_local, high_nodes)
##reduce only top words
feat <-  names(topfeatures(fcm_local, top_n))
fcm_local <- fcm_select(fcmat, pattern = c(tmp, hub))
##text plot
quanteda.textplots::textplot_network(fcm_local, min_freq = 0.1, edge_color = "grey",vertex_color ="#538797")
}
library(ComTxt)
library(ComTxt)
library(ComTxt)
library(dplyr)
library(quanteda)
library(quanteda)
library(tidyr)
library(scales)
library(igraph)
library(topicmodels)
library(maps)
library(purrr)
library(mallet)
library(mallet)
library(stopwords)
library(ggplot2)
example_df<- get_tweet_preprocess(list_tweets, location_country = "spain")
## preprocess : lemmatization, stopwords, urls, emoticons
stop_words <- c(stopwords::stopwords("es", source = "stopwords-iso"))
df_lang.1 <- twitter_preprocess(example_lang.1, ud_lang = "spanish", stop_words)
example_lang.1 <- example_df[example_df$lang == "es", ] ## 80%
df_lang.1 <- twitter_preprocess(example_lang.1, ud_lang = "spanish", stop_words)
keyword_network(df_pre, keyword_remove = "cultura", top_n = 40)
df_lang.2 <- twitter_preprocess(example_lang.2, ud_lang = "english", stop_words)
## stopwords
stop_words <- c(stopwords::stopwords(source ="smart")) ## for english this is working well
df_lang.2 <- twitter_preprocess(example_lang.2, ud_lang = "english", stop_words)
example_lang.2 <- example_df[example_df$lang == "en", ] ##7 %
df_lang.2 <- twitter_preprocess(example_lang.2, ud_lang = "english", stop_words)
df_pre <- rbind(df_lang.1, df_lang.2)
keyword_network(df_pre, keyword_remove = "cultura", top_n = 40)
keyword_table(df_pre, keyword_remove= "cultura", top_n = 10)
example_df <- geo_preprocess(example_df, location_country = "spain" , ##"finland" ##"croatia"
multi_name = c("españa","spagna")) ##c("Suomi")  c("republic of croatia")
example_df<- get_tweet_preprocess(list_tweets, location_country = "spain")
example_df <- geo_preprocess(example_df, location_country = "spain" , ##"finland" ##"croatia"
multi_name = c("españa","spagna")) ##c("Suomi")  c("republic of croatia")
example_df<- get_tweet_preprocess(list_tweets, location_country = "spain")
head(example_df$geo_coords)
geo_table(example_df)
topic_number(df_pre)
library(SparseM)
library(lava)
library(RTextTools)
library(tm)
library(slam)
library(topicmodels)
library(Rmpfr)
## make a plot with
library(ggplot2)
library(grid)
library(gridExtra)
library(textmineR)
library(dplyr)
topic_number(df_pre)
topic_number(df_pre)
df_topics <- twitter_topic(df_pre, n_topic = 7)
topic_wordcloud(df_topics, par_row = 3, par_col = 3, n_topic = 7, maximum_n = 200, cloud_scale = 2.5)
topic_wordcloud(df_topics, n_topic = 7, maximum_n = 200, cloud_scale = 2.5)
df_topics$model$numTopics
topic_wordcloud <- function(mallet_df, par_row = ceiling(sqrt(mallet_df$model$numTopics)), par_col = ceiling(sqrt(mallet_df$model$numTopics)),
n_topic =7,maximum_n = 200, cloud_scale = 2.5){
pal2 <- brewer.pal(8,"Dark2")
par(mfrow = c(par_row, par_col),     # 2x2 layout
oma = c(2, 2, 0, 0), # two rows of text at the outer left and bottom margin
mar = c(1, 1, 0, 0), # space for one row of text at ticks and to separate plots
mgp = c(2, 1, 0),    # axis label at 2 rows distance, tick labels at 1 row
xpd = NA)
topic.words <- mallet.topic.words(mallet_df, smoothed = T, normalized = T)
mallet_words_list <- list()
for (i in 1:as.numeric(n_topic)) {
mallet_words_list[[i]] <- mallet.top.words(mallet_df, topic.words[i,], maximum_n)
}
topic_mallet_list <- mallet_words_list
for(i in 1:length(topic_mallet_list)){
df_words <- as.data.frame(topic_mallet_list[i])
wordcloud(df_words$words, df_words$weights, scale = c(cloud_scale,.2),
max.words = maximum_n, random.order = FALSE, rot.per = .15, colors = pal2, main = "Mallet wordcloud")
}
}
topic_wordcloud(df_topics, n_topic = 7, maximum_n = 200, cloud_scale = 2.5)
library(RColorBrewer)
library(wordcloud)
topic_wordcloud(df_topics, n_topic = 7, maximum_n = 200, cloud_scale = 2.5)
class(mallet_df$model$numTopics)
class(df_topics$model$numTopics)
as.numeric(df_topics$model$numTopics)
topic_wordcloud <- function(mallet_df, par_row = ceiling(sqrt(mallet_df$model$numTopics)), par_col = ceiling(sqrt(mallet_df$model$numTopics)),
n_topic = mallet_df$model$numTopics, maximum_n = 200, cloud_scale = 2.5){
pal2 <- brewer.pal(8,"Dark2")
par(mfrow = c(par_row, par_col),     # 2x2 layout
oma = c(2, 2, 0, 0), # two rows of text at the outer left and bottom margin
mar = c(1, 1, 0, 0), # space for one row of text at ticks and to separate plots
mgp = c(2, 1, 0),    # axis label at 2 rows distance, tick labels at 1 row
xpd = NA)
topic.words <- mallet.topic.words(mallet_df, smoothed = T, normalized = T)
mallet_words_list <- list()
for (i in 1:as.numeric(n_topic)) {
mallet_words_list[[i]] <- mallet.top.words(mallet_df, topic.words[i,], maximum_n)
}
topic_mallet_list <- mallet_words_list
for(i in 1:length(topic_mallet_list)){
df_words <- as.data.frame(topic_mallet_list[i])
wordcloud(df_words$words, df_words$weights, scale = c(cloud_scale,.2),
max.words = maximum_n, random.order = FALSE, rot.per = .15, colors = pal2, main = "Mallet wordcloud")
}
}
topic_wordcloud(df_topics, maximum_n = 200, cloud_scale = 2.5)
##words in topic
topic_getwords <- function(mallet_df, n_topic = mallet_df$model$numTopics, n_words = 500){
topic.words <- mallet.topic.words(mallet_df, smoothed = T, normalized = T)
mallet_words_list <- list()
for (i in 1:as.numeric(n_topic)) {
mallet_words_list[[i]] <- mallet.top.words(mallet_df, topic.words[i,], n_words)
}
topic_mallet_list <- mallet_words_list
topic_mallet <- list.cbind(topic_mallet_list)
print(kable(topic_mallet, "simple"))
}
topic_getwords(df_topics, n_words = 100)
library(rlist)
library(kableExtra)
library(mallet)
topic_getwords(df_topics, n_words = 100)
#create function that accepts the lda model and num word to display
topic_wordplot <- function(mallet_df, n_topic = mallet_df$model$numTopics, num_words = 10) {
topic.words <- mallet.topic.words(mallet_df, smoothed = T, normalized = T)
mallet_words_list <- list()
for (i in 1:as.numeric(n_topic)) {
mallet_words_list[[i]] <- mallet.top.words(mallet_df, topic.words[i,], 100)
}
topic_mallet_list <- mallet_words_list
topic_word <- list.cbind(topic_mallet_list)
## top num_words words per topic
sort <- list()
for(i in 1:n_topic*2-1){
sort[[i]] <- c(i,i+1)
}
sort <- do.call(rbind,sort)
tt <- list()
for(i in 1:nrow(sort)){
tt[[i]] <- cbind(topic = paste("Topic", i), topic_word[,c(sort[i,])])
}
topics_tidy <- do.call(rbind.data.frame, tt)
theme_lyrics <- function(aticks = element_blank(),
pgminor = element_blank(),
lt = element_blank(),
lp = "none")
{
theme(plot.title = element_text(hjust = 0.5), #center the title
axis.ticks = aticks, #set axis ticks to on or off
panel.grid.minor = pgminor, #turn on or off the minor grid lines
legend.title = lt, #turn on or off the legend title
legend.position = lp) #turn on or off the legend
}
word_chart <- function(data, input, title) {
data %>%
#set y = 1 to just plot one variable and use word as the label
ggplot(aes(as.factor(row), 1, label = input, fill = factor(topic) )) +
#you want the words, not the points
geom_point(color = "transparent") +
#make sure the labels don't overlap
geom_label_repel(nudge_x = .2,
direction = "y",
box.padding = 0.1,
segment.color = "transparent",
size = 3) +
facet_grid(~topic) +
theme_lyrics() +
theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
#axis.title.x = element_text(size = 9),
panel.grid = element_blank(), panel.background = element_blank(),
panel.border = element_rect("lightgray", fill = NA),
strip.text.x = element_text(size = 9)) +
labs(x = NULL, y = NULL, title = title) +
#xlab(NULL) + ylab(NULL) +
#ggtitle(title) +
coord_flip()
}
top_terms <- topics_tidy %>%
group_by(topic) %>%
arrange(topic, desc(weights)) %>%
#get the top num_words PER topic
slice(seq_len(num_words)) %>%
arrange(topic, weights) %>%
#row is required for the word_chart() function
mutate(row = row_number()) %>%
ungroup()
#create a title to pass to word_chart
title <- paste("Mallet Top",num_words  ,"Terms for", n_topic, "Topics")
#call the word_chart function you built in prep work
word_chart(top_terms, top_terms$words, title)
}
##topic_wordsplot
library(dplyr)
library(tidytext)
library(mallet)
library(rlist)
library(ggrepel)
topic_getwords(df_topics, n_words = 100)
topic_wordplot(df_topics,  num_words = 10)
#create function that accepts the lda model and num word to display
topic_radarmap <- function(df ,mallet_df, n_topic = mallet_df$model$numTopics) {
doc.topics.m <- mallet.doc.topics(mallet_df, smoothed=T,
normalized=T)
tmp_df <- df[rep(seq_len(nrow(df)), each = n_topic), ]
#tmp_df$topic <- paste("Topic", rep(1:n_topic,  nrow(df)))
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
tmp_df$topic <- paste("Topic", rep(1:n_topic,  nrow(df)))
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
year_prob <- aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
select(created_at, topic, year_topic_n = n)
year_topic$prob <- year_prob$x
year_topic$percent <- year_topic$prob / year_topic$year_topic_n *100
col <- col2rgb(c("peachpuff", "royalblue", "tomato", "#B4CF68", "green", "purple", "orange","grey","red","#8DD3C7" , "pink", "blue","gold"))
#Join the two and create a percent field
year_radar_chart <- year_topic %>%
select(-year_topic_n, -prob) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "Topic Radar", colMatrix =col)
print(year_radar_chart)
}
topic_radarmap(df_pre, df_topics, n_topic = 7)
library(dplyr)
library(tidytext)
library(ggplot2)
library(scales)
library(mallet)
library(radarchart)
topic_radarmap(df_pre, df_topics, n_topic = 7)
topic_radarmap(df_pre, df_topics)
shiny_topic <- function(mallet_df, df){
require(shiny)
require(ggrepel)
theme_lyrics <- function(aticks = element_blank(),
pgminor = element_blank(),
lt = element_blank(),
lp = "none")
{
theme(plot.title = element_text(hjust = 0.5), #center the title
axis.ticks = aticks, #set axis ticks to on or off
panel.grid.minor = pgminor, #turn on or off the minor grid lines
legend.title = lt, #turn on or off the legend title
legend.position = lp) #turn on or off the legend
}
word_chart <- function(data, input, title) {
data %>%
#set y = 1 to just plot one variable and use word as the label
ggplot(aes(as.factor(row), 1, label = input, fill = factor(topic) )) +
#you want the words, not the points
geom_point(color = "transparent") +
#make sure the labels don't overlap
geom_label_repel(nudge_x = .2,
direction = "y",
box.padding = 0.1,
segment.color = "transparent",
size = 3) +
facet_grid(~topic) +
theme_lyrics() +
theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
#axis.title.x = element_text(size = 9),
panel.grid = element_blank(), panel.background = element_blank(),
panel.border = element_rect("lightgray", fill = NA),
strip.text.x = element_text(size = 9)) +
labs(x = NULL, y = NULL, title = title) +
#xlab(NULL) + ylab(NULL) +
#ggtitle(title) +
coord_flip()
}
shinyApp(
ui = navbarPage(
sidebarLayout(
sidebarPanel(
#numericInput("n_topic", "Number K", 7, min = 2, max = 100),
numericInput("num_words", "Number Words", 10, min = 2, max = 50)),
mainPanel(
tabsetPanel(type = "tabs",
tabPanel("Topic words plot", jqui_resizable(plotOutput("topic_word"))),
tabPanel("Topic radar map", jqui_resizable(chartJSRadarOutput("topic_radar")))
)
)
)
),
server = function(input,output) {
top_terms <- reactive({
topic.words <- mallet.topic.words(mallet_df, smoothed = T, normalized = T)
mallet_words_list <- list()
for (i in 1:as.numeric(mallet_df$model$numTopics)) {
mallet_words_list[[i]] <- mallet.top.words(mallet_df, topic.words[i,], 100)
}
topic_mallet_list <- mallet_words_list
topic_word <- list.cbind(topic_mallet_list)
## top num_words words per topic
sort <- list()
for(i in 1:mallet_df$model$numTopics*2-1){
sort[[i]] <- c(i,i+1)
}
sort <- do.call(rbind,sort)
tt <- list()
for(i in 1:nrow(sort)){
tt[[i]] <- cbind(topic = paste("Topic", i), topic_word[,c(sort[i,])])
}
topics_tidy <- do.call(rbind.data.frame, tt)
top_terms <- topics_tidy %>%
group_by(topic) %>%
arrange(topic, desc(weights)) %>%
#get the top num_words PER topic
slice(seq_len(input$num_words)) %>%
arrange(topic, weights) %>%
#row is required for the word_chart() function
mutate(row = row_number()) %>%
ungroup()
return(top_terms)
})
title <- reactive({
paste("Mallet Top",input$num_words  ,"Terms for",mallet_df$model$numTopics, "Topics")
})
output$topic_word <- renderPlot(
#call the word_chart function you built in prep work
word_chart(top_terms(), top_terms()$words, title())
)
year_topic <- reactive({
doc.topics.m <- mallet.doc.topics(mallet_df, smoothed=T,
normalized=T)
tmp_df <- df[rep(seq_len(nrow(df)), each = mallet_df$model$numTopics), ]
#tmp_df$topic <- paste("Topic", rep(1:n_topic,  nrow(df)))
tt <- list()
for(i in 1:nrow(doc.topics.m)){
tt[[i]] <- doc.topics.m[i,]
}
tmp_df$prob <- unlist(tt)
tmp_df$topic <- paste("Topic", rep(1:mallet_df$model$numTopics,  nrow(df)))
tmp_df$created_at <- format(as.Date(tmp_df$created_at), "%Y")
year_prob <- aggregate(x = tmp_df$prob,                # Specify data column
by = list(tmp_df$topic, tmp_df$created_at),              # Specify group indicator
FUN = sum)
year_topic <- tmp_df  %>%
group_by(created_at, topic) %>%
count(created_at, topic) %>%
select(created_at, topic, year_topic_n = n)
year_topic$prob <- year_prob$x
year_topic$percent <- year_topic$prob / year_topic$year_topic_n *100
return(year_topic)
})
col <- reactive({
col2rgb(c("peachpuff", "royalblue", "tomato", "#B4CF68", "green", "purple", "orange","grey","red","#8DD3C7" , "pink", "blue","gold"))
})
#Join the two and create a percent field
year_radar_chart <- reactive({
year_radar_chart <- year_topic() %>%
select(-year_topic_n, -prob) %>%
spread(created_at, percent)
return(year_radar_chart)
})
output$topic_radar <- renderChartJSRadar(
chartJSRadar(year_radar_chart(), showToolTipLabel = TRUE,
main = "Topic Radar", colMatrix =col())
)
}
)
}
shiny_topic(df_topics, df_pre)
library(shinydashboard)
library(shiny)
library(reactable)
library(dplyr)
library(tidytext)
library(mallet)
library(rlist)
library(ggrepel)
library(mallet)
library(stopwords)
library(scales)
library(tidyr)
library(radarchart)
library(shinyjqui)
shiny_topic(df_topics, df_pre)
library(ComTxt)
