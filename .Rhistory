}
twitter_sentiment(basic_tweets, c("shit", "bullshit"))
df <- basic_tweets
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3) %>% #Words like "ah" or "oo" used in music
#anti_join(stop_words)
anti_join(stopwords::stopwords(language = "es", source = "stopwords-iso"))
undesirable_words <- c("holy shit", "bullshit", "fucking", "shit", "damn")
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3) %>% #Words like "ah" or "oo" used in music
#anti_join(stop_words)
anti_join(stopwords::stopwords(language = "es", source = "stopwords-iso"))
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3) %>% #Words like "ah" or "oo" used in music
anti_join(stop_words)
stopwords::stopwords(language = "es", source = "stopwords-iso")
stop_words
class(stop_words)
d <- as.table(stopwords::stopwords(language = "es", source = "stopwords-iso"))
d <- as.tbl(stopwords::stopwords(language = "es", source = "stopwords-iso"))
d <- stopwords::stopwords(language = "es", source = "stopwords-iso")
d_1 <- as.table(d)
View(d)
tbl(d)
class(d)
d_1 <- as.data.frame(d)
tbl(d)
class(d)
d_1 <- data.frame(d)
class(d_1$d)
tbl(d_1)
tbl_df(d_1)
as_tibble(d_1)
stopwords <- as.data.frame(word = stopwords::stopwords(language = "es", source = "stopwords-iso"))
stopwords <- data.frame(word = stopwords::stopwords(language = "es", source = "stopwords-iso"))
stopwords
stopwords$lexicon <- "es"
stopwords <- as_tibble(stopwords)
stopwords
stop_words
stopwords <- data.frame(word = stopwords::stopwords(language = "es", source = "stopwords-iso"))
stopwords$lexicon <- "es"
stopwords <- as_tibble(stopwords)
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3) %>% #Words like "ah" or "oo" used in music
anti_join(stopwords)
twitter_sentiment <- function(df, language, undesirable_words){
stopwords <- data.frame(word = stopwords::stopwords(language = language, source = "stopwords-iso"))
stopwords$lexicon <- language
stopwords <- as_tibble(stopwords)
#Create tidy text format: Unnested, Unsummarized, -Undesirables, Stop and Short words
nrc_tidy <- df %>%
unnest_tokens(word, text) %>% #Break the lyrics into individual words
filter(!word %in% undesirable_words) %>% #Remove undesirables
filter(!nchar(word) < 3) %>% #Words like "ah" or "oo" used in music
anti_join(stopwords)
youtube_nrc <- nrc_tidy %>%
inner_join(get_sentiments("nrc"))
}
twitter_sentiment(basic_tweets,"en", c("shit", "bullshit"))
d <- twitter_sentiment(basic_tweets,"en", c("shit", "bullshit"))
Vew(d)
View(d)
class(d$created_at)
head(d$created_at)
as.Date(head(d$created_at), "%m/%d/%Y")
as.POSIXlt.POSIXct(head(d$created_at), tz = tz)
as.POSIXlt.POSIXct(head(d$created_at), tz = '%m/%Y')
as.POSIXlt(head(d$created_at), format="%d/%m/%Y")
as.POSIXlt(head(d$created_at), format="%m/%Y")
format(head(d$created_at),"%m")
format(head(d$created_at),"%m/%Y")
## sentiment of bar chart per year :: NEED TO PREPROCESS PER MONTH/ YEAR
bar_sentiment <- function(df){
df$month <- format(df$created_at,"%m/%Y")
df$year <- format(df$created_at, "%Y")
df %>%
group_by(month, sentiment) %>%
summarise(word_count = n()) %>%
ungroup() %>%
mutate(sentiment = reorder(sentiment, word_count)) %>%
#Use `fill = -word_count` to make the larger bars darker
ggplot(aes(sentiment, word_count, fill = sentiment)) +
geom_col() +
facet_wrap(~video_name)+
#guides(fill = FALSE)+ #Turn off the legend
labs(x = "sentiment" , y = "Word Count") +
theme(axis.text.x = element_blank())+
ggtitle("NRC Sentiment")
}
library(ggplot2) #Visualizations (also included in the tidyverse package)
library(ggrepel) #`geom_label_repel`
library(gridExtra) #`grid.arrange()` for multi-graphs
library(knitr) #Create nicely formatted output tables
library(kableExtra) #Create nicely formatted output tables
library(formattable) #For the color_tile function
library(circlize) #Visualizations - chord diagram
library(memery) #Memes - images with plots
library(magick) #Memes - images with plots (image_read)
library(yarrr)  #Pirate plot
library(radarchart) #Visualizations
library(igraph) #ngram network diagrams
library(ggraph) #
bar_sentiment(d)
## sentiment of bar chart per year :: NEED TO PREPROCESS PER MONTH/ YEAR
bar_sentiment <- function(df){
df$month <- format(df$created_at,"%m/%Y")
df$year <- format(df$created_at, "%Y")
df %>%
group_by(month, sentiment) %>%
summarise(word_count = n()) %>%
ungroup() %>%
mutate(sentiment = reorder(sentiment, word_count)) %>%
#Use `fill = -word_count` to make the larger bars darker
ggplot(aes(sentiment, word_count, fill = sentiment)) +
geom_col() +
facet_wrap(~month)+
#guides(fill = FALSE)+ #Turn off the legend
labs(x = "sentiment" , y = "Word Count") +
theme(axis.text.x = element_blank())+
ggtitle("NRC Sentiment")
}
bar_sentiment(d)
## sentiment of bar chart per year :: NEED TO PREPROCESS PER MONTH/ YEAR
bar_sentiment <- function(df){
df$month <- format(df$created_at,"%m/%Y")
df$year <- format(df$created_at, "%Y")
df %>%
group_by(month, sentiment) %>%
summarise(word_count = n()) %>%
ungroup() %>%
mutate(sentiment = reorder(sentiment, word_count)) %>%
#Use `fill = -word_count` to make the larger bars darker
ggplot(aes(sentiment, word_count, fill = sentiment)) +
geom_col() +
facet_wrap(~month)+
#guides(fill = FALSE)+ #Turn off the legend
labs(x = "sentiment" , y = "Word Count") +
#theme(axis.text.x = element_blank())+
ggtitle("NRC Sentiment")
}
bar_sentiment(d)
## sentiment of bar chart per year :: NEED TO PREPROCESS PER MONTH/ YEAR
bar_sentiment <- function(df){
df$month <- format(df$created_at,"%m/%Y")
df$year <- format(df$created_at, "%Y")
df %>%
group_by(month, sentiment) %>%
summarise(word_count = n()) %>%
ungroup() %>%
mutate(sentiment = reorder(sentiment, word_count)) %>%
#Use `fill = -word_count` to make the larger bars darker
ggplot(aes(sentiment, word_count, fill = sentiment)) +
geom_col() +
facet_wrap(~month)+
#guides(fill = FALSE)+ #Turn off the legend
labs(x = "sentiment" , y = "Word Count") +
#theme(axis.text.x = element_blank())+
ggtitle("NRC Sentiment")+
theme(legend.position = "none")
}
bar_sentiment(d)
## sentiment of bar chart per year :: NEED TO PREPROCESS PER MONTH/ YEAR
bar_sentiment <- function(df, by = "%m%Y"){
df$created_at <- format(df$created_at, by)
df %>%
group_by(created_at, sentiment) %>%
summarise(word_count = n()) %>%
ungroup() %>%
mutate(sentiment = reorder(sentiment, word_count)) %>%
ggplot(aes(sentiment, word_count, fill = sentiment)) +
geom_col() +
facet_wrap(~created_at)+
labs(x = "sentiment" , y = "Word Count") +
ggtitle("NRC Sentiment")+
theme(legend.position = "none")
}
bar_sentiment(d, "%m%Y")
bar_sentiment(d, "%Y")
library(RColorBrewer)
?brewer.pal()
brewer.pal(10, "Accent")
my_colors <- c(brewer.pal(8, "Accent"), brewer.pal(8, "Dark2"), brewer.pal(12, "Paired"))
i = 1
unique(df$created_at)[[i]]
unique(df$created_at)
my_colors <- c(brewer.pal(8, "Accent"), brewer.pal(8, "Dark2"), brewer.pal(12, "Paired"))
grid.col <- list()
for(i in 1:length(unique(d$month))){
grid.col[[i]] <- c(unique(d$month)[[i]] = my_colors[i] )
}
grid.col = c("Reddeadredemption2" = my_colors[1], "Godofwar" = my_colors[2], "Darksouls" = my_colors[3], "Zelda" = my_colors[4], "Thelastofus" = my_colors[5], "Thewitcher3" = my_colors[6],"Horizonzerodawn" = my_colors[7],"Sekiro" = my_colors[8],"Deathstranding" = my_colors[9],"Starwarsjedi" = my_colors[10],"Animalcrossing" = my_colors[11],"UnderstandingLOU2" = my_colors[12], "ReviewingLOU2" = my_colors[13],"anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
grid.col
d$month <- format(d$created_at, "%m/%Y")
for(i in 1:length(unique(d$month))){
grid.col[[i]] <- c(unique(d$month)[[i]] = my_colors[i] )
}
grid.col <- c(unique(d$month)[[i]] = my_colors[i] )
unique(d$month)[[i]]
grid.col <- c( "02/2021" = my_colors[i] )
length(unique(df$month))
nrow(unique(df$month))
unique(df$month)
unique(d$month)
length(unique(d$month))
grid.col <- c( unique(d$month) = my_colors[i] )
grid.col = c("Reddeadredemption2" = my_colors[1], "Godofwar" = my_colors[2], "Darksouls" = my_colors[3], "Zelda" = my_colors[4], "Thelastofus" = my_colors[5], "Thewitcher3" = my_colors[6],"Horizonzerodawn" = my_colors[7],"Sekiro" = my_colors[8],"Deathstranding" = my_colors[9],"Starwarsjedi" = my_colors[10],"Animalcrossing" = my_colors[11],"UnderstandingLOU2" = my_colors[12], "ReviewingLOU2" = my_colors[13],"anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
grid.col = c( unique(d$month) = my_colors[i] )
grid.col = c("Reddeadredemption2" = my_colors[1], "Godofwar" = my_colors[2], "Darksouls" = my_colors[3], "Zelda" = my_colors[4], "Thelastofus" = my_colors[5], "Thewitcher3" = my_colors[6],"Horizonzerodawn" = my_colors[7],"Sekiro" = my_colors[8],"Deathstranding" = my_colors[9],"Starwarsjedi" = my_colors[10],"Animalcrossing" = my_colors[11],"UnderstandingLOU2" = my_colors[12], "ReviewingLOU2" = my_colors[13],"anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
grid.col
dd <unique(d$month)
dd <-unique(d$month)
grid.col = c( dd = my_colors[i] )
grid.col = c( dd[1] = my_colors[i] )
dd[1]
grid.col <- list()
for(i in 1:length(unique(d$month))){
date <- unique(d$month)[[i]]
grid.col[[i]] <- c(date= my_colors[i] )
}
grid.col <-unlist(grid.col)
grid.col
grid.col<- c(unique(d$month)= my_colors[i] )
grid.col<- c(data = my_colors[i] )
date <- unique(d$month)[[i]]
grid.col<- c(date = my_colors[i] )
grid.col
unique(d$month)
grid.col<- c("02/2021" = my_colors[i] )
grid.col<- c(unique(d$month) = my_colors[i] )
grid.col<- c(unique(d$month) == my_colors[i] )
grid.col
grid.col<- c(unique(d$month) = my_colors[i] )
class(grid.col)
grid.col<- c("02/2021" = my_colors[i] )
class(grid.col)
grid.col
## circos map -----------------------------------------------------
circos_map <- function(df, by){
df$created_at <- format(df$created_at, "%Y")
my_colors <- c(brewer.pal(8, "Accent"), brewer.pal(8, "Dark2"), brewer.pal(12, "Paired"))
#grid.col = c("02/2021" = my_colors[1], "01/2021" = my_colors[2], "12/2020" = my_colors[3], "11/2020" = my_colors[4], "10/2020" = my_colors[5], "9/2020" = my_colors[6],"8/2020" = my_colors[7],"7/2020" = my_colors[8],"6/2020" = my_colors[9],"5/2020" = my_colors[10],"4/2020" = my_colors[11],"3/2020" = my_colors[12], "2/2020" = my_colors[13],"1/2020" = my_colors[14],"12/2019" = my_colors[15],"11/2019" = my_colors[16],"10/2019" = my_colors[17],"9/2019" = my_colors[18],"8/2019" = my_colors[19],"7/2019" = my_colors[20],"6/2019" = my_colors[21],"5/2019" = my_colors[22],"4/2019" = my_colors[23],"3/2019" = my_colors[24],"2/2019" = my_colors[25],"1/2019" = my_colors[26],"anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
my_colors <- c(brewer.pal(8, "Accent"), brewer.pal(8, "Dark2"), brewer.pal(12, "Paired"))
grid.col = c("2021" = my_colors[1], "2020" = my_colors[2], "2019" = my_colors[3], "anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
decade_mood <-  df %>%
filter(!sentiment %in% c("positive", "negative")) %>%
count(sentiment, created_at) %>%
group_by(created_at, sentiment) %>%
summarise(sentiment_sum = sum(n)) %>%
ungroup()
circos.clear()
#Set the gap size
circos.par(gap.after = c(rep(5, length(unique(decade_mood[[1]])) - 1), 15,
rep(5, length(unique(decade_mood[[2]])) - 1), 15))
chordDiagram(decade_mood, grid.col = grid.col, transparency = .2,annotationTrack = c("grid", "axis"))
circos.track(track.index = 1, panel.fun = function(x, y) {
circos.text(CELL_META$xcenter, CELL_META$ylim[1], CELL_META$sector.index,
facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.3))
}, bg.border = NA)
title("Relationship Between Mood and Years")
}
circos_map <- function(df){
df$created_at <- format(df$created_at, "%Y")
my_colors <- c(brewer.pal(8, "Accent"), brewer.pal(8, "Dark2"), brewer.pal(12, "Paired"))
#grid.col = c("02/2021" = my_colors[1], "01/2021" = my_colors[2], "12/2020" = my_colors[3], "11/2020" = my_colors[4], "10/2020" = my_colors[5], "9/2020" = my_colors[6],"8/2020" = my_colors[7],"7/2020" = my_colors[8],"6/2020" = my_colors[9],"5/2020" = my_colors[10],"4/2020" = my_colors[11],"3/2020" = my_colors[12], "2/2020" = my_colors[13],"1/2020" = my_colors[14],"12/2019" = my_colors[15],"11/2019" = my_colors[16],"10/2019" = my_colors[17],"9/2019" = my_colors[18],"8/2019" = my_colors[19],"7/2019" = my_colors[20],"6/2019" = my_colors[21],"5/2019" = my_colors[22],"4/2019" = my_colors[23],"3/2019" = my_colors[24],"2/2019" = my_colors[25],"1/2019" = my_colors[26],"anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
my_colors <- c(brewer.pal(8, "Accent"), brewer.pal(8, "Dark2"), brewer.pal(12, "Paired"))
grid.col = c("2021" = my_colors[1], "2020" = my_colors[2], "2019" = my_colors[3], "anger" = "grey", "anticipation" = "grey", "disgust" = "grey", "fear" = "grey", "joy" = "grey", "sadness" = "grey", "surprise" = "grey", "trust" = "grey")
decade_mood <-  df %>%
filter(!sentiment %in% c("positive", "negative")) %>%
count(sentiment, created_at) %>%
group_by(created_at, sentiment) %>%
summarise(sentiment_sum = sum(n)) %>%
ungroup()
circos.clear()
#Set the gap size
circos.par(gap.after = c(rep(5, length(unique(decade_mood[[1]])) - 1), 15,
rep(5, length(unique(decade_mood[[2]])) - 1), 15))
chordDiagram(decade_mood, grid.col = grid.col, transparency = .2,annotationTrack = c("grid", "axis"))
circos.track(track.index = 1, panel.fun = function(x, y) {
circos.text(CELL_META$xcenter, CELL_META$ylim[1], CELL_META$sector.index,
facing = "clockwise", niceFacing = TRUE, adj = c(0, 0.3))
}, bg.border = NA)
title("Relationship Between Mood and Years")
}
circos_map(d)
## each words used in each video---------------------------------------
plot_words <- function(df){
plot_words_UnderstandingLOU2 <- df %>%
group_by(sentiment) %>%
count(word, sort = TRUE) %>%
arrange(desc(n)) %>%
slice(seq_len(10)) %>%
ungroup()
plot_words_UnderstandingLOU2 %>%
ggplot(aes(word, 1, label = word, fill = sentiment )) +
geom_point(color = "transparent") +
geom_label_repel(force = 1,nudge_y = .5,
direction = "y",
box.padding = 0.05,
segment.color = "transparent",
size = 3) +
facet_grid(~sentiment) +
theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
axis.title.x = element_text(size = 6),
panel.grid = element_blank(), panel.background = element_blank(),
panel.border = element_rect("lightgray", fill = NA),
strip.text.x = element_text(size = 9)) +
xlab(NULL) + ylab(NULL) +
ggtitle("NRC Sentiment words plot") +
coord_flip()
}
plot_words(d)
## each words used in each video---------------------------------------
plot_words <- function(df){
plot_words_UnderstandingLOU2 <- df %>%
group_by(sentiment) %>%
count(word, sort = TRUE) %>%
arrange(desc(n)) %>%
slice(seq_len(10)) %>%
ungroup()
plot_words_UnderstandingLOU2 %>%
ggplot(aes(word, 1, label = word, fill = sentiment )) +
geom_point(color = "transparent") +
geom_label_repel(force = 1,nudge_y = .5,
direction = "y",
box.padding = 0.05,
segment.color = "transparent",
size = 3) +
facet_grid(~sentiment) +
theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
axis.title.x = element_text(size = 6),
panel.grid = element_blank(), panel.background = element_blank(),
panel.border = element_rect("lightgray", fill = NA),
strip.text.x = element_text(size = 9)) +
xlab(NULL) + ylab(NULL) +
ggtitle("NRC Sentiment words plot") +
coord_flip()+
theme(legend.position = "none")
}
plot_words(d)
## sentiment radarmap ------------------------------
radar_map <- function(){
df$created_at <- format(df$created_at, "%Y")
prince_nrc_sub <- df %>%
filter(!sentiment %in% c("positive", "negative"))
year_sentiment_nrc <- prince_nrc_sub %>%
group_by(created_at, sentiment) %>%
count(created_at, sentiment) %>%
select(created_at, sentiment, sentiment_year_count = n)
#Get the total count of sentiment words per video_name (not distinct)
total_sentiment_video <- prince_nrc_sub %>%
count(created_at) %>%
select(created_at, year_total = n)
col <- col2rgb(c("peachpuff", "royalblue", "tomato", "#B4CF68", "green", "purple", "orange","grey","red","#8DD3C7" , "pink", "blue","gold"))
#Join the two and create a percent field
year_radar_chart <- year_sentiment_nrc %>%
inner_join(total_sentiment_video, by = "created_at") %>%
mutate(percent = sentiment_year_count / year_total * 100 ) %>%
#filter(year %in% c("1978","1994","1995")) %>%
select(-sentiment_year_count, -year_total) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "NRC video Radar", colMatrix =col)
print(year_radar_chart)
}
radar_map(d)
## sentiment radarmap ------------------------------
radar_map <- function(df){
df$created_at <- format(df$created_at, "%Y")
prince_nrc_sub <- df %>%
filter(!sentiment %in% c("positive", "negative"))
year_sentiment_nrc <- prince_nrc_sub %>%
group_by(created_at, sentiment) %>%
count(created_at, sentiment) %>%
select(created_at, sentiment, sentiment_year_count = n)
#Get the total count of sentiment words per video_name (not distinct)
total_sentiment_video <- prince_nrc_sub %>%
count(created_at) %>%
select(created_at, year_total = n)
col <- col2rgb(c("peachpuff", "royalblue", "tomato", "#B4CF68", "green", "purple", "orange","grey","red","#8DD3C7" , "pink", "blue","gold"))
#Join the two and create a percent field
year_radar_chart <- year_sentiment_nrc %>%
inner_join(total_sentiment_video, by = "created_at") %>%
mutate(percent = sentiment_year_count / year_total * 100 ) %>%
#filter(year %in% c("1978","1994","1995")) %>%
select(-sentiment_year_count, -year_total) %>%
spread(created_at, percent) %>%
chartJSRadar(showToolTipLabel = TRUE,
main = "NRC video Radar", colMatrix =col)
print(year_radar_chart)
}
radar_map(d)
## Semantic network for anger and fear sadness---------------------
sentiment_semantic <- function(df, select = "anger"){
select_nrc <- df %>%
filter(sentiment %in% select)
user_data <- unique(select_nrc$authorDisplayName)
net <- list()
for (i in 1:length(user_data)){
if(length(select_nrc[select_nrc$authorDisplayName == user_data[i],]$word)>1){
word <- paste(unique(select_nrc[select_nrc$authorDisplayName == user_data[i],]$word), sep = "", collapse = " ")
} else {
word<- select_nrc[select_nrc$authorDisplayName == user_data[i],]$word
}
net[[i]] <- as.data.frame(cbind(id = user_data[i], word))
}
net_anger <- do.call(rbind, net)
library(quanteda)
library(quanteda.textplots)
tweets_dfm <- dfm(net_anger$word) # Document-feature matrix
#tag_dfm <- dfm_select(tweets_dfm, pattern = ("#*")) # Get hashtags
toptag <- names(topfeatures(tweets_dfm, 100)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(tweets_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
textplot_network(topgat_fcm, min_freq = 12, edge_alpha = 0.5, edge_size = 5, edge_color = "grey",vertex_color ="#538797")
}
sentiment_semantic(d, select = "anger")
select_nrc <- d %>%
filter(sentiment %in% "surprize")
sentiment_semantic(d, select = "surprise")
select_nrc <- d %>%
filter(sentiment %in% "surprize")
View(select_nrc)
View(d)
select_nrc <- d %>%
filter(sentiment %in% "surprise")
View(select_nrc)
sentiment_semantic <- function(df, select = "surprise"){
select_nrc <- df %>%
filter(sentiment %in% select)
user_data <- unique(select_nrc$status_id)
net <- list()
for (i in 1:length(user_data)){
if(length(select_nrc[select_nrc$status_id == user_data[i],]$word)>1){
word <- paste(unique(select_nrc[select_nrc$status_id == user_data[i],]$word), sep = "", collapse = " ")
} else {
word<- select_nrc[select_nrc$status_id == user_data[i],]$word
}
net[[i]] <- as.data.frame(cbind(id = user_data[i], word))
}
net_anger <- do.call(rbind, net)
tweets_dfm <- dfm(net_anger$word) # Document-feature matrix
#tag_dfm <- dfm_select(tweets_dfm, pattern = ("#*")) # Get hashtags
toptag <- names(topfeatures(tweets_dfm, 100)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(tweets_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
textplot_network(topgat_fcm, min_freq = 12, edge_alpha = 0.5, edge_size = 5, edge_color = "grey",vertex_color ="#538797")
}
sentiment_semantic(d, select = "surprise")
## Semantic network for anger and fear sadness---------------------
library(quanteda)
library(quanteda.textplots)
sentiment_semantic(d, select = "surprise")
select_nrc <- d %>%
filter(sentiment %in% "surprise")
user_data <- unique(select_nrc$status_id)
net <- list()
for (i in 1:length(user_data)){
if(length(select_nrc[select_nrc$status_id == user_data[i],]$word)>1){
word <- paste(unique(select_nrc[select_nrc$status_id == user_data[i],]$word), sep = "", collapse = " ")
} else {
word<- select_nrc[select_nrc$status_id == user_data[i],]$word
}
net[[i]] <- as.data.frame(cbind(id = user_data[i], word))
}
net_anger <- do.call(rbind, net)
tweets_dfm <- dfm(net_anger$word) # Document-feature matrix
#tag_dfm <- dfm_select(tweets_dfm, pattern = ("#*")) # Get hashtags
toptag <- names(topfeatures(tweets_dfm, 100)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(tweets_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
textplot_network(topgat_fcm, min_freq = 12, edge_alpha = 0.5, edge_size = 5, edge_color = "grey",vertex_color ="#538797")
textplot_network(topgat_fcm, min_freq = 1, edge_alpha = 0.5, edge_size = 5, edge_color = "grey",vertex_color ="#538797")
textplot_network(topgat_fcm,  edge_alpha = 0.5, edge_size = 5, edge_color = "grey",vertex_color ="#538797")
sentiment_semantic <- function(df, select = "surprise", n_nodes = 100){
select_nrc <- df %>%
filter(sentiment %in% select)
user_data <- unique(select_nrc$status_id)
net <- list()
for (i in 1:length(user_data)){
if(length(select_nrc[select_nrc$status_id == user_data[i],]$word)>1){
word <- paste(unique(select_nrc[select_nrc$status_id == user_data[i],]$word), sep = "", collapse = " ")
} else {
word<- select_nrc[select_nrc$status_id == user_data[i],]$word
}
net[[i]] <- as.data.frame(cbind(id = user_data[i], word))
}
net_anger <- do.call(rbind, net)
tweets_dfm <- dfm(net_anger$word) # Document-feature matrix
#tag_dfm <- dfm_select(tweets_dfm, pattern = ("#*")) # Get hashtags
toptag <- names(topfeatures(tweets_dfm, n_nodes)) # Most important hashtags; we dont want to plot every hashtag
tag_fcm <- fcm(tweets_dfm) # Feature-occurance matrix which shows the network structure
topgat_fcm <- fcm_select(tag_fcm, pattern = toptag) # Filter results so that we plot only 50 top hashtags
textplot_network(topgat_fcm,  edge_alpha = 0.5, edge_size = 5, edge_color = "grey",vertex_color ="#538797")
}
sentiment_semantic(d, select = "surprise")
sentiment_semantic(d, select = "surprise", n_nodes = 200)
sentiment_semantic(d, select = "anger", n_nodes = 200)
sentiment_semantic(d, select = "joy", n_nodes = 200)
sentiment_semantic(d, select = "anticipation", n_nodes = 200)
